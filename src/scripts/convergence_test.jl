using Distributed
using Turing
using Dates
addprocs(4)


@everywhere using ReverseDiffDSGE
@everywhere using Random
@everywhere using Zygote
@everywhere using Turing
@everywhere using Distributions
@everywhere using ComponentArrays
@everywhere using SharedArrays
using DataFrames
using CSV

# Estimation parameters
nperiods = 100
B = [1,5,6]  # observables
Ïƒ_obs = 0.01 # sd of measurement error shocks

## Likelihood related functions
@everywhere logll(Î¸,ys) = kalman_ll(blanchardkahn(HerbstSchorfheide(Î¸)),ys,B,Ïƒ_obs)


## Generate fake data
Î¸ = rand.(ğ’«â‚•â‚›);
println("True parameter values:")
println("Î¸ = $(round.(Î¸,digits=2))")

ts(Î¸,B,Ïƒ_obs,nperiods) = ReverseDiffDSGE.timeseries(blanchardkahn(HerbstSchorfheide(Î¸)),nperiods)[:,B] +
        Ïƒ_obs*rand(Normal(),nperiods,length(B)); # ad hoc measurement error shocks
ys = ts(Î¸,B,Ïƒ_obs,nperiods)

Î¸_axes = getaxes(Î¸);

## Turing Model
@everywhere @model function m(y)

        Ï„â»Â¹ ~ InverseGamma(8,8)
        Îº   ~ Uniform(0.0,1.0)
        Ïˆ_1 ~ Gamma(4,1/8)
        Ïˆ_2 ~ Gamma(4,1/8)
        Ï_R ~ Uniform(0.5,0.9)
        Ï_g ~ Uniform(0.90,0.99)
        Ï_z ~ Uniform(0.90,0.99)
        Ïƒ_R ~ InverseGamma(4,0.32)
        Ïƒ_g ~ InverseGamma(4,2.0)
        Ïƒ_z ~ InverseGamma(4,0.5)

        Ï = ComponentArray([Î¸.rA,Ï„â»Â¹,Îº,Ïˆ_1,Ïˆ_2,Ï_R,Ï_g,Ï_z,Ïƒ_R,Ïƒ_g,Ïƒ_z],Î¸_axes)

        @Turing.addlogprob! logll(Ï,y)

end

_nuts  = (alg = NUTS{Turing.ZygoteAD}(0.65;max_depth=5,Î”_max=500.0,init_Ïµ=0.1),iters = (500,1_000))
_mh    = (alg = MH(),iters = (250_000,500_000,1_000_000))

algs = (_nuts,_mh)

println("# Precompilation")
for alg in algs
        sample(m(ys), alg.alg, MCMCDistributed(), 1, 4)
end

# Dataframe to collect results
df = DataFrame(
        values = [],
        algorithm = [],
        iterations = [],
        elapsed = [],
        gelmanrubin = [],
        ess = [],
        rhat = [],
)

function test_function(alg,iters,Î¸,ys)
        ch = sample(m(ys), alg, MCMCDistributed(), iters, 4)
        results = (
                values = round.(Î¸,digits=2),
                algorithm = alg,
                iterations = iters,
                elapsed = maximum(ch.info.stop_time - ch.info.start_time),
                gelmanrubin = maximum(gelmandiag(ch).nt.psrf),
                ess = minimum(ess(ch).nt.ess),
                rhat = maximum(ess(ch).nt.rhat)
        )
        println("Estimates")
        display(describe(ch)[1])
        return results
end


for Î¸_i in 1:20

        global Î¸ = rand.(ğ’«â‚•â‚›);
        global ys = ts(Î¸,B,Ïƒ_obs,nperiods);
        println("-----------------------------------------------------------------------")
        println("True values")
        display(DataFrame([NamedTuple(round.(Î¸;digits=2))]))
        println("Prior means")
        display(DataFrame([NamedTuple(round.(mean.(ğ’«â‚•â‚›);digits=2))]))
        for alg in algs
                println("-----------------------------------------------------------------------")
                println("Algorithm:    $(alg.alg)")
                println("Iterations:   $(alg.iters)")
                println("Current time: $(Dates.format(now(),"HH:MM"))")
                for mcmc_iters in alg.iters
                        try
                                results = test_function(alg.alg,mcmc_iters,Î¸,ys)
                                push!(df,results)
                                println("Results so far:")
                                display(df[:,[:iterations,:elapsed,:gelmanrubin,:ess,:rhat]])
                                CSV.write("results/benchmarktests.csv",df;delim=";")
                        catch
                                println("-----------------------------------------------------------------------")
                                println("Error. Trying new estimator.")
                                println("-----------------------------------------------------------------------")
                        end
                end
        end

end
